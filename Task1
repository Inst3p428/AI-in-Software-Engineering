1. Short Answer Questions
#Q1: Explain how AI-driven code generation tools (e.g., GitHub Copilot) reduce development time. What are their limitations?
AI resources such as GitHub  By automatically recommending code fragments, boilerplate, and even entire functions based on context, Copilot shortens the development time. 
They facilitate learning by example, speed up routine coding, and minimize errors.
Limitations: If trained on faulty datasets, they may produce unsafe or inaccurate code, have a poor grasp of business logic, and propagate bias.

#Q2: Compare supervised and unsupervised learning in the context of automated bug detection.
Using labeled data, such as bug or no bug, supervised learning is used.  If properly trained, it can accurately predict bugs.
Without labels, unsupervised learning can identify anomalies, or unexpected patterns helpful for unidentified bugs, however it could produce false positives.

#Q3: Why is bias mitigation critical when using AI for user experience personalization?
Algorithms for personalization may ignore minorities and give preference to dominant user groups.
AI can exclude users or perpetuate prejudices if bias mitigation is not implemented.
By identifying and lessening these prejudices, tools such as IBM AI Fairness 360 enhance inclusivity.
